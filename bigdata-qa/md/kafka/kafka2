1.kafka的分区副本机制，讲一下你的理解？
它的副本就是指topic分区的副本。暂时起到的作用就是数据备份，保证数据的安全性。
这些分区副本分布在不同的broker上，当leader副本所在的broker宕机时，保证节点可用。
消费者并不能从非leader副本中读取数据。
kafka的分区有leader and follower之分。
follower副本从leader副本拉取数据。

2.当生产者发送消息到主分区之后，数据是如何同步到其他分区的呢？
leader副本是如何选出来的？很简单，只是取位于ISR中的第一个副本。
kafka的副本机制比较严格，数据只能写入到leader副本，follower副本只能异步拉取leader分区
的提交日志进行同步。
当leader副本所在的broker挂掉时，依托zookeeper的znode的watcher机制，kafka可以感知到。
会从ISR(同步副本）中选择一个作为新的leader副本。

3.kafka的分区副本既不能分散读，有什么好处呢？
1.方便实现 read-your-writes,因为读写都是同一个broker的副本，所以刚写入的数据都可以
被读出来，而如果使用副本读，副本读是需要时间的，可能没有同步过来。
2.方便实现 单调读
道理同上，数据的写入和读取都是从同一个broker来读取的。

4.ISR?follower副本进入ISR的标准是什么？
leader副本天然就在ISR中，除非它所在的broker宕机。
标准是broker端参数replica.lag.time.max.ms 参数值，follower副本能够落后于leader副本的
最长时间，默认值是10秒。即发现follower在超过这个时间的间隔没有向leader 复制数据的时候，
就会把它从follower从ISR移除掉。
那这个时间是怎么取到的？就是直接从副本的leo的时间来对比，可以取到时间字段。

follower副本是按什么步骤拉取leader分区的副本吗？
follower副本同步的速度如果慢于leader副本的写入速度，那么在超过replica.lag.time.max.ms中，
就会被在ISR中移除。
那follower副本是按什么频率去向leader 副本请求的呢？
没有配置，不断请求，只取决于它的写入速度。

ISR是一个动态集合，如果follower副本追上来，就会再一次加入ISR.
broker端的参数unclean.leader.election.selection.enabled控制是否允许非同步副本参加leader
副本的选举。
如果允许的时候，就是提高了可用性A.选 C 或者 选 A可以由用户确定。

5.关于分区副本的leo,hw,举个例子?
一个主题有三个分区，leader分区，fp1,fp2，生产者向leader副本写入了10条消息，而fp1同步了5条数据，
而fp2同步了3条数据，则hw是多少？leo是多少？
leo是分区级别的，leader的leo是10，而分区的leo就是总条数的下一个。
而hw是从min(isr leo)所以可以发现是hw=3。
消费者只能消费三条数据，虽然写入了10条数据。

6.假如一个分区有5个副本，broker的min.insync.replicas=2,而且producer端配置的是acks=all,
这时producer怎么判定数据写入成功？
producer在acks=all判定数据写入成功的条件是ISR中所有副本都写入到了消息，但producer没有指定
ISR中需要有几个副本，所以需要min.insync.replicas参数，譬如ISR中只有1个副本，则不满足参数
配置的最小值2的时候，则会报异常，无法保存消息。

7.kafka中的请求是如何被处理的？
kafka中的请求使用reactor模式进行处理。
Reactor是事件驱动架构的一种实现方式，适用于多个客户端并发请求服务端的场景。
Reactor有一个请求分发线程dispatcher,叫Acceptor,它接收到请求后转发到后端的工作线程池。
Kafka 提供了 Broker 端参数 num.network.threads，用于调整该网络线程池的线程数。
其默认值是 3，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求。
Acceptor使用轮询的方式公平地把请求发送到网络线程池线程。

当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个共享请求队列中。
Broker 端还有个 IO 线程池，负责从该队列中取出请求，执行真正的处理。
如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；
如果是 FETCH 请求，则从磁盘或页缓存中读取消息。IO 线程池处中的线程才是执行请求逻辑的线程。
Broker 端参数 num.io.threads 控制了这个线程池中的线程数。
目前该参数默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。
你可以根据实际硬件条件设置此线程池的个数。

8.讲一下你对kafka controller的理解？
它是kafka的核心组件，在zk的帮助下管理kafka集群。
每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。官网上有个名为 activeController 的 JMX 指标，
可以帮助我们实时监控控制器的存活状态。这个 JMX 指标非常关键，你在实际运维操作过程中，一定要实时查看这个指标的值。
当集群启动后，Kafka 怎么确认控制器位于哪台 Broker 呢？实际上，Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。
Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。
控制器到底有哪些协调作用？
 a.主题管理 增加删除与分区添加 执行kafka-topic脚本的处理
 b.分区重分配  kafka-reassign-partitions
 c.集群成员管理broker相关 控制器组件会利用 Watch 机制检查 ZooKeeper 的 /brokers/ids 节点下的子节点数量变更
 d.数据服务  控制器上保存了最全的集群元数据信息，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。

9.关于高水位和leader epoch?
在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息。消费者只能消费已提交消息。
事务机制会影响消费者所能看到的消息的范围，它不只是简单依赖高水位来判断。
它依靠一个名为 LSO（Log Stable Offset）的位移值来判断事务型消费者的可见性。
位移值等于高水位的消息也属于未提交消息。也就是说，高水位上的消息是不能被消费者消费的。
高水位和 LEO 是副本对象的两个重要属性
分区的高水位就是其 Leader 副本的高水位。
关于leader副本的高水位怎么计算？
可以认为是ISR中所有副本的leo的最小值。  currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}。
leader副本上会同时保存一份其他副本的leo 和hw的值。
当leader副本的leo更新时，当本地的远程副本更新时，都会重新计算其高水位值。
高水位的更新落后于fetch，总是需要在最新的一次拉取中，根据传入的offset来更新自身的hw信息，这是一个潜在的数据丢失的点
Leader 副本高水位更新和 Follower 副本高水位更新在时间上是存在错配的。这种错配是很多“数据丢失”或“数据不一致”问题的根源。
因为这个时候如果恰好leader副本所在broker宕机的话，接管的isr的hw还没有更新，导致数据丢失？
leo hw之间有差异，但是leo的数据是对的啊，为什么不能使用leo的数据呢？
Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。
Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。
每次有 Leader 变更时，新的 Leader 副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。

